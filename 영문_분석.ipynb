{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob # 경로와 이름을 지정해 파일 처리 작업\n",
    "import re\n",
    "from functools import reduce # 2차원 리스트 -> 1차원 리스트\n",
    "\n",
    "# nltk : 자연어 처리 패키지\n",
    "from nltk.tokenize import word_tokenize # 단어 토큰화\n",
    "from nltk.corpus import stopwords # 불용어 정보 제공\n",
    "from nltk.stem import WordNetLemmatizer # 표제어 추출 \n",
    "\n",
    "from collections import Counter # 갯수 자동 계산\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS # wordcloud용 불용어\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "nltk.download() # 최초 한번은 nltk의 리소스를 다운로드 받아야함.\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "all_files = glob.glob('data/myCabinetExcelData*.xls')\n",
    "all_files\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "all_files_data = [] \n",
    "\n",
    "for file in all_files:\n",
    "    data_frame = pd.read_excel(file)\n",
    "    all_files_data.append(data_frame)\n",
    "\n",
    "all_files_data[0].head()\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "all_files_data_concat = pd.concat(all_files_data, axis= 0 , ignore_index=True)\n",
    "all_files_data_concat.tail()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "all_files_data_concat.to_csv('data/riss_AI.csv', encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "all_title = all_files_data_concat['제목']\n",
    "all_title\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "lemma = WordNetLemmatizer() # 표제어 추출 작업\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "words = []  \n",
    "\n",
    "for title in all_title:\n",
    "    EnWords = re.sub(r\"[^a-zA-Z]+\", \" \", str(title))\n",
    "    EnWordsToken = word_tokenize(EnWords.lower())\n",
    "    EnWordsTokenStop = [w for w in EnWordsToken if w not in stopWords]\n",
    "    EnWordsTokenStopLemma = [lemma.lemmatize(word) for word in EnWordsTokenStop]\n",
    "    words.append(EnWordsTokenStopLemma)\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "print(words[:5])\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "words2 = list(reduce(lambda x , y : x+y, words))\n",
    "print(words2)\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "count = Counter(words2)\n",
    "count\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "word_count = dict()\n",
    "\n",
    "for tag, counts in count.most_common(50):\n",
    "    if(len(str(tag)) > 1):\n",
    "        word_count[tag] = counts \n",
    "        print(\"%s : %d\" %(tag, counts))\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "del word_count['ai']\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.xlabel(\"word\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid(True)\n",
    "\n",
    "sorted_Keys = sorted(word_count, key=word_count.get, reverse=True)\n",
    "sorted_Values = sorted(word_count.values(), reverse=True)\n",
    "\n",
    "plt.bar(range(len(word_count)), sorted_Values, align='center')\n",
    "plt.xticks(range(len(word_count)), list(sorted_Keys), rotation='90')# x축 눈금\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "all_files_data_concat['doc_count'] = 0\n",
    "summary_year = all_files_data_concat.groupby('출판일', as_index=False)['doc_count'].count()\n",
    "summary_year\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"doc-count\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.plot(range(len(summary_year)), summary_year['doc_count'])\n",
    "plt.xticks(range(len(summary_year)), [y for y in summary_year['출판일']], rotation='90')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "wc = WordCloud(background_color='white', colormap='autumn', stopwords=stopwords\n",
    "              , width=1000, height=600)\n",
    "cloud = wc.generate_from_frequencies(word_count)\n",
    "\n",
    "plt.imshow(cloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
